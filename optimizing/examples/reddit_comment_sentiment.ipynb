{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What does Reddit think about the new MBP?\n",
    "### Is it da bomb, or did it just bomb?\n",
    "[**Run this notebook in binder**](http://mybinder.org:/repo/knowsuchagency/mpb-sentiment-analysis-example)\n",
    "\n",
    "My friends and I have been talking today about Apple's announcement of their new Macbook Pro line.\n",
    "I personally own an Apple TV, Ipad mini, Macbook Pro, and an iPhone. I was definitely looking forward\n",
    "to see what Apple was going to come out with the new Macbook Pro line. My thoughts on the announcement aside,\n",
    "it seemed to me like the overwhelming majority of users on Reddit [didn't come away very impressed](https://www.reddit.com/r/apple/comments/59plnp/lets_talk_about_those_prices/) with the announcements Apple made in regards to the new Macbook Pro. I thought this would be a good opportunity to play with Reddit's API and to try out some rudimentary sentiment analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tech\n",
    "\n",
    "To talk to Reddit, I'm using the aptly named, [**PRAW**](https://praw.readthedocs.io/en/stable/index.html) library. PRAW stands for the Python Reddit Api Wrapper. Nice.\n",
    "\n",
    "Now for the sentiment analysis, I'm going to use the [**TextBlob**](https://textblob.readthedocs.io/en/dev/) library. TextBlob is a library that provides an easy to use interface for a lot of common natural language processing tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the data\n",
    "\n",
    "To begin, we instantiate praw's Reddit class with an appropriate user agent. Be careful how you define your user agent. Doing so incorrectly can get you banned according to Reddit. Fortunately, writing a user agent isn't hard at all. You can find the official documentation on how to do so on the [Reddit API wiki page](https://github.com/reddit/reddit/wiki/API). \n",
    "\n",
    "As of this writing, the format should look something like this (taken from the aformentioned wiki):\n",
    "\n",
    "    <platform>:<app ID>:<version string> (by /u/<reddit username>)\n",
    "\n",
    "Example: \n",
    "\n",
    "    User-Agent: android:com.example.myredditapp:v1.2.3 (by /u/kemitche)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['375 :: Apple Keynote, October 2016 | Post-Event Megathread',\n",
       " '44 :: Pre-order Shipping Megathread | Mac Lineup, 2016',\n",
       " \"4942 :: Let's talk about those prices...\",\n",
       " \"3027 :: I dont mind the lack of standard USB, but you're telling me I can't u...\",\n",
       " '1759 :: Tim Cook: \"We think technology should be available to everyone\" and t...',\n",
       " '1147 :: (UK) 13\" MacBook Pro has gone from £999 to £1449',\n",
       " \"741 :: What is Apple's definition of a pro?\",\n",
       " \"725 :: Let's talk about the touch bar.\",\n",
       " '617 :: Gone is lit Apple logo on the back of Macbook Pro',\n",
       " '487 :: What are you thoughts on the new MacBook Pros? Being honest I am not i...']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import praw\n",
    "\n",
    "# I saved my user agent string in a local file\n",
    "# since one should use their own\n",
    "with open('./.user_agent') as f:\n",
    "    user_agent = f.read()\n",
    "\n",
    "# instantiate Reddit connection class\n",
    "r = praw.Reddit(user_agent=user_agent)\n",
    "\n",
    "# let's get the current top 10 submissions\n",
    "# since praw interacts with reddit lazily, we wrap the method\n",
    "# call in a list\n",
    "submissions = list(r.get_subreddit('apple').get_hot(limit=10))\n",
    "[str(s) for s in submissions]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cool, so we have some data. From looking at the actual subreddit in a browser, we can see the two top submissions are official threads so we'll just skip over them.\n",
    "\n",
    "<a href=\"http://imgur.com/8MJXgdg\"><img src=\"http://i.imgur.com/8MJXgdg.png\" title=\"source: imgur.com\" /></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"4942 :: Let's talk about those prices...\",\n",
       " \"3027 :: I dont mind the lack of standard USB, but you're telling me I can't u...\",\n",
       " '1759 :: Tim Cook: \"We think technology should be available to everyone\" and t...',\n",
       " '1147 :: (UK) 13\" MacBook Pro has gone from £999 to £1449',\n",
       " \"741 :: What is Apple's definition of a pro?\",\n",
       " \"725 :: Let's talk about the touch bar.\",\n",
       " '617 :: Gone is lit Apple logo on the back of Macbook Pro',\n",
       " '487 :: What are you thoughts on the new MacBook Pros? Being honest I am not i...']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submissions = submissions[2:]\n",
    "[str(s) for s in submissions]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submission 1\n",
    "\n",
    "We'll start by looking at the comments in the first submission about Apple's new pricing. Can you guess what people think?!\n",
    "\n",
    "In praw, every Submission has a comments attribute which is iterable. This attribute isn't homogeneous. That is, some of the items will be Comment objects, and there may be a MoreComments class in there as well, so we'll need to handle that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I\\'m still trying to figure out what justifies a $200 increase on the 13\" ***without*** the Touch Bar...',\n",
       " \"Probably shouldn't have been surprised, but it hit me like a slippery fish. My jaw dropped.\\n\\nThey've priced me out, sadly.\",\n",
       " '$4300 to max out the 15 pro...lol',\n",
       " \"I was waiting for the new Macbooks to replace my water damaged 2015 Macbook Pro.\\n\\nNow, I'm off to Apple Store to get my Macbook fixed. These prices are insane.\",\n",
       " 'As an Australian, I am expecting to be even less thrilled when regional pricing is revealed. ',\n",
       " '2000 euros here in Germany. I am shocked. Really',\n",
       " \"Ain't paying that much. May have to stick with my base model 2012 air :(\",\n",
       " \"Even without the TouchBar, it is still $1500. \\n$200 over the last year's MacBook Pro. \\nThe price increase is just insane. \",\n",
       " \"Unfortunately Apple deserves a stiff reality check from consumers after this.  They'll keep inflating prices with minimal improvements unless we make a statement by NOT BUYING their stuff.  They need to get grounded in the sense that they're just not far ahead of the competition as far as aesthetics go anymore.  There's no reason to pay thoese prices except for that logo, and they hope that's reason enough that you'll buy it.  They're so wrong.\\n\\nRemember when Microsoft announced Xbox One with the DRM...remember the outcry and the lousy sales actually prompted a positive change from Microsoft and since then, the Xbox and MS has completely recovered.  We need to give Apple the same reality check, because it'll help them find their way again.\\n\\nDo not buy this crap.\",\n",
       " 'Well the Macbook that I am typing on will be the last one that I use...',\n",
       " '$2399USD for a Quad Core i7, 16GB of 2133Mhz RAM, 256GB SSD, and an AMD 400 mobile series, but not even the 480RX equivalent?\\n\\nFuck right off. ',\n",
       " \"As expected, this has made Microsoft's Surface line extremely attractive.\",\n",
       " \"I was getting hyped for my new Macbook Pro for the entire keynote only to find out that it's $500 out of my budget at the end. It's like a mouse being lured in by cheese only to get whacked by a mousetrap.\",\n",
       " 'Rip students...',\n",
       " \"What. The. Fuck.\\n\\n+ $200 for better processor? okay I guess, I can live with that\\n\\n+ $400 for 1TB of space? seems a bit much but okay\\n\\n+ **$1200 for 2TB?!** Are they fucking joking?\\n\\n+ $100 for better graphics? seems pointless, they could just include the 460 version by default, they are just milking money at this point\\n\\nSad, really sad. It's been two years and if we want a better model than the 2015, we need to pay about $1000 extra...\\n\\nApple products are already the most expensive products on the market and it seems like they are heading for a direction where everything is just going to get more expensive. Wouldn't be surprised if the next best model of iPhone would be $1500 or something like that.\",\n",
       " 'The base price with 512GB I would have accepted, but 256 is way too low. \\n\\nAlso a Canadian\\n\\nedit: GB, sorry typo',\n",
       " 'This is the mac mini all over again.',\n",
       " 'By far the most disappointing Apple event ever.',\n",
       " 'That price is STUPID. I was really excited, especially with the space gray, but the price makes me not want this at all. ',\n",
       " \"let's talk about releasing two flagship products within months of each other that require a dongle to work together.\"]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# grab the first submission\n",
    "submission = submissions[0]\n",
    "\n",
    "# the actual text is in the body\n",
    "# attribute of a Comment\n",
    "def get_comments(submission, n=20):\n",
    "    \"\"\"\n",
    "    Return a list of comments from a submission.\n",
    "    \n",
    "    We can't just use submission.comments, because some\n",
    "    of those comments may be MoreComments classes and those don't\n",
    "    have bodies.\n",
    "    \n",
    "    n is the number of comments we want to limit ourselves to\n",
    "    from the submission.\n",
    "    \"\"\"\n",
    "    count = 0\n",
    "    def barf_comments(iterable=submission.comments):\n",
    "        \"\"\"\n",
    "        This generator barfs out comments.\n",
    "        \n",
    "        Some comments seem not to have bodies, so we skip those.\n",
    "        \"\"\"\n",
    "        nonlocal count\n",
    "        for c in iterable:\n",
    "            if hasattr(c, 'body') and count < n:\n",
    "                count += 1\n",
    "                yield c.body\n",
    "            elif hasattr(c, '__iter__'):\n",
    "                # handle MoreComments classes\n",
    "                yield from barf_comments(c)\n",
    "            else:\n",
    "                # c was a Comment and did not have a body\n",
    "                continue\n",
    "    return barf_comments()\n",
    "                \n",
    "comments = list(get_comments(submission))\n",
    "list(comments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment analysis!\n",
    "\n",
    "So now we have the first twenty comments of the first submission.\n",
    "\n",
    "We'll combine them into one piece of text and determine the overall sentiment from them.\n",
    "\n",
    "According to the TextBlob docs, this is how to use their sentiment analysis api and how to interpret it\n",
    "\n",
    "\n",
    "### The sentiment property returns a namedtuple of the form Sentiment(polarity, subjectivity). The polarity score is a float within the range [-1.0, 1.0]. The subjectivity is a float within the range [0.0, 1.0] where 0.0 is very objective and 1.0 is very subjective.\n",
    "\n",
    "```\n",
    ">>> testimonial = TextBlob(\"Textblob is amazingly simple to use. What great fun!\")\n",
    ">>> testimonial.sentiment\n",
    "Sentiment(polarity=0.39166666666666666, subjectivity=0.4357142857142857)\n",
    ">>> testimonial.sentiment.polarity\n",
    "0.39166666666666666\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentiment(polarity=-0.06283927712499143, subjectivity=0.5978612657184086)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from textblob import TextBlob\n",
    "\n",
    "comment_blob = TextBlob(''.join(comments))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Huh, things aren't looking good so far. Well, let's look at more data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "more_comments = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for submission in submissions:\n",
    "    more_comments.extend(get_comments(submission, 200))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "404"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(more_comments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I figure there are many more than 404 comments for those submissions. I suspect we only get that many because praw [tries to do the right thing](https://praw.readthedocs.io/en/stable/pages/faq.html) and follow Reddit's guidelines for the amount of requests one can make within a given time limit. We're not going to worry about that now. 404 comments is good enough since we're only tinkering :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17046\n"
     ]
    }
   ],
   "source": [
    "bigger_blob = TextBlob(''.join(more_comments))\n",
    "\n",
    "# The first time I ran this method, it failed\n",
    "# because I hadn't read TextBlob's docs closely\n",
    "# and downloaded the corpus of text in needed.\n",
    "# python -m textblob.download_corpora\n",
    "\n",
    "print(len(bigger_blob.words))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see what some of the most common words are"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('no', 43),\n",
       " ('about', 42),\n",
       " ('has', 42),\n",
       " ('can', 39),\n",
       " ('there', 39),\n",
       " ('when', 38),\n",
       " ('from', 37),\n",
       " ('screen', 37),\n",
       " ('iPhone', 37),\n",
       " ('going', 37),\n",
       " (\"'re\", 36),\n",
       " ('Touch', 36),\n",
       " ('out', 35),\n",
       " ('even', 35),\n",
       " ('only', 34),\n",
       " ('15', 32),\n",
       " ('been', 32),\n",
       " ('too', 31),\n",
       " ('buy', 30),\n",
       " ('know', 30),\n",
       " ('we', 30),\n",
       " ('than', 30),\n",
       " ('up', 29),\n",
       " ('13', 29),\n",
       " ('people', 28),\n",
       " ('because', 28),\n",
       " ('time', 28),\n",
       " ('same', 27),\n",
       " ('They', 27),\n",
       " ('model', 27),\n",
       " ('which', 27),\n",
       " ('way', 26),\n",
       " ('other', 26),\n",
       " ('using', 26),\n",
       " ('prices', 26),\n",
       " ('still', 25),\n",
       " ('see', 25),\n",
       " ('by', 25),\n",
       " ('down', 25),\n",
       " ('Bar', 25)]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "counter = Counter(bigger_blob.words)\n",
    "\n",
    "# the most common words are pretty mundane common parts of speech, so we'll skip the first few\n",
    "counter.most_common()[60:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finally, let's see what the over all sentiment analysis is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentiment(polarity=0.07565960941292733, subjectivity=0.52062214346886)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigger_blob.sentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the overall sentiment is much more positive when we include a larger body of comments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## In conclusion\n",
    "\n",
    "We've hopefully learned a little more about communicating with Reddit using Python and doing some simple sentiment analysis on the content there. This wasn't meant to be a very scientific excercise, but I thought it was a fun way to play around with [PRAW](https://praw.readthedocs.io/en/stable/index.html) and [TextBlob](https://textblob.readthedocs.io/en/dev/index.html). Both libraries are really powerful and simple to use and I can definitely see myself taking advantage of them a lot more in the future. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
